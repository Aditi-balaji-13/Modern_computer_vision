{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ix5dQS2rUMlu"
   },
   "source": [
    "# **EE5178: Panoramic Stitching**\n",
    "## -B Aditi\n",
    "##  MM19B022\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1pbCZ5UYRC_"
   },
   "source": [
    "# Brief Overview\n",
    "\n",
    "In this problem set, you will implement panoramic stitching. Given two input images, we will \"stitch\" them together to create a simple panorama. To construct the image panorama, we will use concepts learned in class such as keypoint detection, local invariant descriptors, RANSAC, and perspective warping. \n",
    "\n",
    "The panoramic stitching algorithm consists of four main steps which we ask you to implement in individual functions:\n",
    "\n",
    "1. Detect keypoints and extract local invariant descriptors from two input images. \n",
    "\n",
    "2. Match the descriptors between the two images.\n",
    "\n",
    "3. Apply RANSAC to estimate a homography matrix between the extracted features.\n",
    "\n",
    "4. Apply a perspective transformation using the homography matrix to merge image into a panorama.\n",
    "\n",
    "Functions to implement (refer to function comments for more detail):\n",
    "\n",
    "1. get_features\n",
    "\n",
    "2. match_keypoints\n",
    "\n",
    "3. find_homography and transform_ransac \n",
    "\n",
    "4. panoramic_stitching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_Cst4k4tuBc"
   },
   "source": [
    "# Starting\n",
    "\n",
    "Run the following code to import the modules you'll need. After your finish the assignment, remember to run all cells and save the note book to your local machine as a .ipynb file for Canvas submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ew8LEUHAceu"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yh--2mn_CR8t"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! wget -O img1.jpg \"https://drive.google.com/uc?export=download&id=1omMydL6ADxq_vW5gl_1EFhdzT9kaMhUt\"\n",
    "! wget -O img2.jpg \"https://drive.google.com/uc?export=download&id=12lxB1ArAlwGn97XgBgt-SFyjE7udMGvf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAFn8q5KYJU8"
   },
   "source": [
    "# Visualize Input Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STBPsFfaCsGJ"
   },
   "outputs": [],
   "source": [
    "img1 = plt.imread('img1.jpg')\n",
    "img2 = plt.imread('img2.jpg')\n",
    "\n",
    "def plot_imgs(img1, img2):\n",
    "  fig, ax = plt.subplots(1, 2, figsize=(15, 20))\n",
    "  for a in ax:\n",
    "    a.set_axis_off()\n",
    "  ax[0].imshow(img1)\n",
    "  ax[1].imshow(img2)\n",
    "\n",
    "plot_imgs(img1, img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvzDOMxBaEog"
   },
   "source": [
    "# Compute SURF/ SIFT/ ORB Features and Match Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ewamv8ZiN70l"
   },
   "outputs": [],
   "source": [
    "def get_features(img):\n",
    "  '''\n",
    "    Compute SURF/SIFT/ORB features using cv2 library functions. Use default parameters when computing the keypoints.\n",
    "    Input: \n",
    "      img: cv2 image\n",
    "    Returns:\n",
    "      keypoints: a list of cv2 keypoints\n",
    "      descriptors: a list of feature descriptors\n",
    "  '''\n",
    "  # ===============================================\n",
    "  # TODO\n",
    "  # ===============================================\n",
    "  return keypoints, descriptors\n",
    "\n",
    "def match_keypoints(desc_1, desc_2, ratio=0.75):\n",
    "  '''\n",
    "    You may use cv2 library functions.\n",
    "    Input:\n",
    "      desc_1, desc_2: list of feature descriptors\n",
    "    Return:\n",
    "      matches: list of feature matches\n",
    "  '''\n",
    "  # ===============================================\n",
    "  # TODO\n",
    "  # ===============================================\n",
    "  return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8D1v4eswOmFR"
   },
   "outputs": [],
   "source": [
    "kp_1, desc_1 = get_features(img1)\n",
    "kp_2, desc_2 = get_features(img2)\n",
    "\n",
    "kp_img1 = cv2.drawKeypoints(img1, kp_1, None, color=(0,255,0), flags=0)\n",
    "kp_img2 = cv2.drawKeypoints(img2, kp_2, None, color=(0,255,0), flags=0)\n",
    "\n",
    "print('keypoints for img1 and img2')\n",
    "plot_imgs(kp_img1, kp_img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwZR6mjW1M3B"
   },
   "outputs": [],
   "source": [
    "matches = match_keypoints(desc_1, desc_2)\n",
    "match_plot = cv2.drawMatches(img1, kp_1, img2, kp_2, matches[:20], None, flags=2)\n",
    "print(\"feature matches\")\n",
    "cv2_imshow(match_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwEgrX9GaXG6"
   },
   "source": [
    "# Compute Homography Matrix using RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ruQFb-euM0iB"
   },
   "outputs": [],
   "source": [
    "def find_homography(pts_1, pts_2):\n",
    "  '''\n",
    "    Implement Direct Linear Transform to find a homography that estimates the transformation mapping from pts_1 to pts_2.\n",
    "    e.g. If x is in pts_1 and y is in pts_2, then y = H * x\n",
    "    Input:\n",
    "      pts_1, pts_1: (N, 2) matrix \n",
    "    Return:\n",
    "      H: the resultant homography matrix (3 x 3)\n",
    "  '''\n",
    "  # ===============================================\n",
    "  # TODO\n",
    "  # ===============================================\n",
    "  return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fD_EKe79-hpl"
   },
   "outputs": [],
   "source": [
    "def transform_ransac(pts_1, pts_2):\n",
    "  '''\n",
    "    Implement RANSAC to estimate homography matrix.\n",
    "    Input:\n",
    "      pts_1, pts_1: (N, 2) matrices\n",
    "    Return:\n",
    "      best_model: homography matrix with most inliers\n",
    "  '''\n",
    "  # ===============================================\n",
    "  # TODO\n",
    "  # ===============================================\n",
    "  return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QL2uHEpLai3V"
   },
   "source": [
    "# Panoramic Stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jV4mhtEo-vbP"
   },
   "outputs": [],
   "source": [
    "def panoramic_stitching(img1, img2):\n",
    "  '''\n",
    "    Generate a panoramic image using the obtained homography matrix.\n",
    "    Input: \n",
    "      img1, img2: cv2 images\n",
    "    Return:\n",
    "      final_img: cv2 image of panorama\n",
    "  '''\n",
    "  # ===============================================\n",
    "  # TODO\n",
    "  # ===============================================\n",
    "  return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3pgxsEQXwlh"
   },
   "outputs": [],
   "source": [
    "result = panoramic_stitching(img1, img2)\n",
    "cv2_imshow(result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Panoramic_Stitching_starters_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
