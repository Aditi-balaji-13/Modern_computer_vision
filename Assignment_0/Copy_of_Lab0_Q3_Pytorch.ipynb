{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Lab0_Q3_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "alrXoCflGKM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b5e916-c7be-4aa0-ffd5-573a7201cfd6"
      },
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pylab as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.21.6\n",
            "1.12.0+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkoWEQE4jf1V"
      },
      "source": [
        "# Pytorch Basics:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiTN0fMclcwt"
      },
      "source": [
        "**Exercise #1:** Torch Tensors\n",
        "\n",
        "**Your Task**: Convert the list to a tensor and check its properties.\n",
        "\n",
        "*   the following list of integers <i>[0, 1, 2, 3, 4]</i> to a torch *int* tensor.\n",
        "*   the following float list <i>[0.0, 1.0, 2.0, 3.0, 4.0]</i> to a torch *float* tensor.\n",
        "*   Convert the torch int tensor to torch float tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIupvreRjfFL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de865aa7-a842-4ae2-f194-c9a783e9d835"
      },
      "source": [
        "# Convert a integer list with length 5 to a tensor\n",
        "int_list = [1,2,3,4,5]\n",
        "# YOUR CODE STARTS HERE\n",
        "ints_to_tensor = torch.tensor(int_list)\n",
        "#YOUR CODE ENDS HERE\n",
        "print(\"The dtype of tensor object after converting it to tensor: \", ints_to_tensor.dtype)\n",
        "print(\"The type of tensor object after converting it to tensor: \", ints_to_tensor.type())\n",
        "print(\"The size of the ints_to_tensor: \", ints_to_tensor.size())\n",
        "print(\"The dimension of the ints_to_tensor: \",ints_to_tensor.ndimension())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dtype of tensor object after converting it to tensor:  torch.int64\n",
            "The type of tensor object after converting it to tensor:  torch.LongTensor\n",
            "The size of the ints_to_tensor:  torch.Size([5])\n",
            "The dimension of the ints_to_tensor:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjxqGezqL2gC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb4ed524-76dd-45fe-d462-c62c5e552cc9"
      },
      "source": [
        "# Convert a float list with length 5 to a tensor\n",
        "float_list = [0.0, 1.0, 2.0, 3.0, 4.0]\n",
        "# YOUR CODE STARTS HERE\n",
        "floats_to_tensor = torch.tensor(float_list)\n",
        "#YOUR CODE ENDS HERE\n",
        "\n",
        "print(\"The dtype of tensor object after converting it to tensor: \", floats_to_tensor.dtype)\n",
        "print(\"The type of tensor object after converting it to tensor: \", floats_to_tensor.type())\n",
        "print(\"The size of the floats_to_tensor: \", floats_to_tensor.size())\n",
        "print(\"The dimension of the floats_to_tensor: \",floats_to_tensor.ndimension())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dtype of tensor object after converting it to tensor:  torch.float32\n",
            "The type of tensor object after converting it to tensor:  torch.FloatTensor\n",
            "The size of the floats_to_tensor:  torch.Size([5])\n",
            "The dimension of the floats_to_tensor:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7g2AIN4MioI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97bb3afc-02a4-4906-d433-806fa8df2754"
      },
      "source": [
        "# Convert the integer list to float tensor\n",
        "old_int_tensor = torch.tensor([0, 1, 2, 3, 4])\n",
        "# YOUR CODE STARTS HERE\n",
        "new_float_tensor = torch.FloatTensor([0, 1, 2, 3, 4])\n",
        "#YOUR CODE ENDS HERE\n",
        "\n",
        "print(\"The type of the new_float_tensor:\", new_float_tensor.type())\n",
        "print(\"The size of the new_float_tensor: \", new_float_tensor.size())\n",
        "print(\"The dimension of the new_float_tensor: \",new_float_tensor.ndimension())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The type of the new_float_tensor: torch.FloatTensor\n",
            "The size of the new_float_tensor:  torch.Size([5])\n",
            "The dimension of the new_float_tensor:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moNAyO_qN3oe"
      },
      "source": [
        "**Exercise #2:** 2D Torch Tensors and 2D numpy arrays\n",
        "\n",
        "**Your Task**: numpy vs. torch\n",
        "\n",
        "*   Convert the given numpy array to a torch tensor; And torch tensor to a numpy array\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV9SfnYAN2y_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0476a69b-86a8-4272-ae14-f23cf558105a"
      },
      "source": [
        "twoD_list = [[11, 12, 13], [21, 22, 23], [31, 32, 33]]\n",
        "twoD_numpy = np.asarray(twoD_list)\n",
        "print(\"The numpy array: \", twoD_numpy)\n",
        "print(\"Type : \", twoD_numpy.dtype)\n",
        "\n",
        "# Convert numpy array to tensor\n",
        "# YOUR CODE STARTS HERE\n",
        "twoD_tensor = torch.from_numpy(twoD_numpy)\n",
        "#YOUR CODE ENDS HERE\n",
        "print(\"\\nNumpy Array -> Tensor:\")\n",
        "print(\"The tensor after converting:\", twoD_tensor)\n",
        "print(\"Type after converting: \", twoD_tensor.dtype)\n",
        "\n",
        "# Convert torch tensor to numpy array\n",
        "# YOUR CODE STARTS HERE\n",
        "new_twoD_numpy = twoD_tensor.numpy()\n",
        "#YOUR CODE ENDS HERE\n",
        "print(\"\\nTensor -> Numpy Array:\")\n",
        "print(\"The numpy array after converting: \", new_twoD_numpy)\n",
        "print(\"Type after converting: \", new_twoD_numpy.dtype)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The numpy array:  [[11 12 13]\n",
            " [21 22 23]\n",
            " [31 32 33]]\n",
            "Type :  int64\n",
            "\n",
            "Numpy Array -> Tensor:\n",
            "The tensor after converting: tensor([[11, 12, 13],\n",
            "        [21, 22, 23],\n",
            "        [31, 32, 33]])\n",
            "Type after converting:  torch.int64\n",
            "\n",
            "Tensor -> Numpy Array:\n",
            "The numpy array after converting:  [[11 12 13]\n",
            " [21 22 23]\n",
            " [31 32 33]]\n",
            "Type after converting:  int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ATEG19PPqsn"
      },
      "source": [
        "**Exercise #3:** 2D Torch Tensors and 2D numpy arrays\n",
        "\n",
        "**Your Task**: Access the different elements of the tensor `twoD_tensor` and numpyarray `twoD_numpy`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWuHGIbnPrjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e19c78-19d8-420a-9188-ec54d06adfbb"
      },
      "source": [
        "# Slice rows 2nd and 3rd row\n",
        "# YOUR CODE STARTS HERE\n",
        "sliced_tensor = twoD_tensor[[1,2]]\n",
        "sliced_numpy = new_twoD_numpy[[1,2]]\n",
        "# YOUR CODE STARTS HERE\n",
        "\n",
        "print(\"Tensor: Result after tensor slicing \", sliced_tensor)\n",
        "print(\"Tensor: Dimension after tensor slicing \", sliced_tensor.ndimension())\n",
        "print(\"Numpy: Result after np slicing: \", sliced_numpy)\n",
        "print(\"Numpy: Dimension after np slicing: \", sliced_numpy.ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: Result after tensor slicing  tensor([[21, 22, 23],\n",
            "        [31, 32, 33]])\n",
            "Tensor: Dimension after tensor slicing  2\n",
            "Numpy: Result after np slicing:  [[21 22 23]\n",
            " [31 32 33]]\n",
            "Numpy: Dimension after np slicing:  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O52E8XJJRxtc"
      },
      "source": [
        "<h2 id=\"Tensor_Op\">Tensor Operations</h2> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1suut6QGZvp"
      },
      "source": [
        "**Exercise #4:** Dot Product\n",
        "\n",
        "In this task, you will implement the dot product function for numpy arrays & torch tensors.\n",
        "\n",
        "The dot product (also known as the scalar product or inner product) is the linear combination of the n real components of two vectors.\n",
        "\n",
        "$$x \\cdot y = x_1 y_1 + x_2 y_2 + \\cdots + x_n y_n$$\n",
        "\n",
        "**Your Task**: Implement the functions `NUMPY_dot` & `PYTORCH_dot`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rNTB943Gjgw"
      },
      "source": [
        "def NUMPY_dot(x, y):\n",
        "    \"\"\"\n",
        "    Dot product of two arrays.\n",
        "\n",
        "    Parameters: \n",
        "    x (numpy.ndarray): 1-dimensional numpy array.\n",
        "    y (numpy.ndarray): 1-dimensional numpy array.\n",
        "\n",
        "    Returns: \n",
        "    numpy.int64: scalar quantity.\n",
        "    \"\"\"\n",
        "    # YOUR CODE STARTS HERE\n",
        "    nd = np.dot(x, y)\n",
        "    # YOUR CODE ends HERE\n",
        "\n",
        "    return nd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdpNs2pAGlEF"
      },
      "source": [
        "def PYTORCH_dot(x, y):\n",
        "    \"\"\"\n",
        "    Dot product of two tensors.\n",
        "\n",
        "    Parameters: \n",
        "    x (torch.Tensor): 1-dimensional torch tensor.\n",
        "    y (torch.Tensor): 1-dimensional torch tensor.\n",
        "\n",
        "    Returns: \n",
        "    torch.int64: scalar quantity.\n",
        "    \"\"\"\n",
        "    # YOUR CODE STARTS HERE\n",
        "    num = torch.dot(x, y)\n",
        "    # YOUR CODE ends HERE\n",
        "\n",
        "    return num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VStlPUWhUTnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3357cfd0-e774-479d-a197-42fc1c175810"
      },
      "source": [
        "# TEST cases\n",
        "X = np.asarray([1,2,3])\n",
        "Y = np.asarray([4,-5,6])\n",
        "print(f'NUMPY: Dot product of {X} and {Y} is {NUMPY_dot(X,Y)}')\n",
        "assert NUMPY_dot(X,Y)==12\n",
        "\n",
        "X = torch.from_numpy(X)\n",
        "Y = torch.from_numpy(Y)\n",
        "print(f'Pytorch: Dot product of {X} and {Y} is {PYTORCH_dot(X,Y)}')\n",
        "assert PYTORCH_dot(X,Y).item()==12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NUMPY: Dot product of [1 2 3] and [ 4 -5  6] is 12\n",
            "Pytorch: Dot product of tensor([1, 2, 3]) and tensor([ 4, -5,  6]) is 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21DOFINXGNCf"
      },
      "source": [
        "**Exercise #5:** Outer Product\n",
        "\n",
        "In this task, you will implement the outer product function for numpy arrays & torch tensors.\n",
        "\n",
        "The outer product (also known as the tensor product) of vectors x and y is defined as\n",
        "\n",
        "$$\n",
        "x \\otimes y =\n",
        "\\begin{bmatrix}\n",
        "x_1 y_1 & x_1 y_2 & … & x_1 y_n\\\\\n",
        "x_2 y_1 & x_2 y_2 & … & x_2 y_n\\\\\n",
        "⋮ & ⋮ & ⋱ & ⋮ \\\\\n",
        "x_m y_1 & x_m y_2 & … & x_m y_n\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "**Your Task**: Implement the functions `NUMPY_outer` & `PYTORCH_outer`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hm0jLIDGOJX"
      },
      "source": [
        "def NUMPY_outer(x, y):\n",
        "    \"\"\"\n",
        "    Compute the outer product of two vectors.\n",
        "\n",
        "    Parameters: \n",
        "    x (numpy.ndarray): 1-dimensional numpy array.\n",
        "    y (numpy.ndarray): 1-dimensional numpy array.\n",
        "\n",
        "    Returns: \n",
        "    numpy.ndarray: 2-dimensional numpy array.\n",
        "    \"\"\"\n",
        "    # YOUR CODE STARTS HERE\n",
        "    out = np.outer(x,y)\n",
        "    # YOUR CODE ends HERE\n",
        "\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEFE0kPkVR3d"
      },
      "source": [
        "def PYTORCH_outer(x, y):\n",
        "    \"\"\"\n",
        "    Compute the outer product of two vectors.\n",
        "\n",
        "    Parameters: \n",
        "    x (torch.Tensor): 1-dimensional torch tensor.\n",
        "    y (torch.Tensor): 1-dimensional torch tensor.\n",
        "\n",
        "    Returns: \n",
        "    torch.Tensor: 2-dimensional torch tensor.\n",
        "    \"\"\"\n",
        "    # YOUR CODE STARTS HERE\n",
        "    out = torch.outer(x,y)\n",
        "\n",
        "    # YOUR CODE ends HERE\n",
        "\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45jAXfICVTE3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ad5e7c9-8aaa-4866-84b4-21c79ce9d576"
      },
      "source": [
        "# TEST cases\n",
        "X = np.asarray([1,2])\n",
        "Y = np.asarray([1,3])\n",
        "print(f'NUMPY: Dot product of {X} and {Y} is \\n{NUMPY_outer(X,Y)}')\n",
        "\n",
        "x = np.array(['a', 'b', 'c'], dtype=object)\n",
        "print(f'NUMPY: Dot product of {X} and {Y} is \\n{NUMPY_outer(x, [1, 2, 3])}')\n",
        "\n",
        "X = torch.from_numpy(X)\n",
        "Y = torch.from_numpy(Y)\n",
        "print(f'Pytorch: Dot product of {X} and {Y} is \\n{PYTORCH_outer(X,Y)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NUMPY: Dot product of [1 2] and [1 3] is \n",
            "[[1 3]\n",
            " [2 6]]\n",
            "NUMPY: Dot product of [1 2] and [1 3] is \n",
            "[['a' 'aa' 'aaa']\n",
            " ['b' 'bb' 'bbb']\n",
            " ['c' 'cc' 'ccc']]\n",
            "Pytorch: Dot product of tensor([1, 2]) and tensor([1, 3]) is \n",
            "tensor([[1, 3],\n",
            "        [2, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQotAIuzYiqM"
      },
      "source": [
        "**Exercise #6:** Hadamard Product\n",
        "\n",
        "In this task, you will implement the Hadamard product function, `multiply`, for numpy arrays & torch tensors.\n",
        "\n",
        "The Hadamard product (also known as the Schur product or entrywise product) of vectors x and y is defined as\n",
        "\n",
        "$$\n",
        "x \\circ y =\n",
        "\\begin{bmatrix}\n",
        "x_{1} y_{1} & x_{2} y_{2} & … & x_{n} y_{n}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "**Your Task**: Implement the functions `NUMPY_multiply` & `PYTORCH_multiply`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9_9W6BCYjmr"
      },
      "source": [
        "def NUMPY_multiply(x, y):\n",
        "    \"\"\"\n",
        "    Multiply arguments element-wise.\n",
        "\n",
        "    Parameters: \n",
        "    x (numpy.ndarray): 1-dimensional numpy array.\n",
        "    y (numpy.ndarray): 1-dimensional numpy array.\n",
        "\n",
        "    Returns: \n",
        "    numpy.ndarray: 1-dimensional numpy array.\n",
        "    \"\"\"\n",
        "    # YOUR CODE STARTS HERE\n",
        "    mult = np.multiply(x, y)\n",
        "    # YOUR CODE ends HERE\n",
        "\n",
        "    return mult"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3-91qalYplz"
      },
      "source": [
        "def PYTORCH_multiply(x, y):\n",
        "    \"\"\"\n",
        "    Multiply arguments element-wise.\n",
        "\n",
        "    Parameters: \n",
        "    x (torch.Tensor): 1-dimensional torch tensor.\n",
        "    y (torch.Tensor): 1-dimensional torch tensor.\n",
        "\n",
        "    Returns: \n",
        "    torch.Tensor: 1-dimensional torch tensor.\n",
        "    \"\"\"\n",
        "    # YOUR CODE STARTS HERE\n",
        "    mult = torch.multiply(x, y)\n",
        "    # YOUR CODE ends HERE\n",
        "\n",
        "    return mult"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3PzQ-9CYq5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e6a3f8c-eae1-40c1-9350-9bd908972846"
      },
      "source": [
        "# TEST cases\n",
        "X = np.asarray([1,2,3])\n",
        "Y = np.asarray([4,-5,6])\n",
        "print(f'NUMPY: Dot product of {X} and {Y} is {NUMPY_multiply(X,Y)}')\n",
        "\n",
        "X = torch.from_numpy(X)\n",
        "Y = torch.from_numpy(Y)\n",
        "print(f'Pytorch: Dot product of {X} and {Y} is {PYTORCH_multiply(X,Y)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NUMPY: Dot product of [1 2 3] and [ 4 -5  6] is [  4 -10  18]\n",
            "Pytorch: Dot product of tensor([1, 2, 3]) and tensor([ 4, -5,  6]) is tensor([  4, -10,  18])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpInjaNXaA12"
      },
      "source": [
        "**Exercise #7:** ReLU\n",
        "\n",
        "In this task, you will implement the ReLU activation function for numpy arrays and torch tensors.\n",
        "\n",
        "The ReLU activation (also known as the rectifier or rectified linear unit) matrix Z resulting from applying the ReLU function to matrix X is defined such that for $X,Z \\in M_{m \\times n} (\\mathbb{R})$, \n",
        "\n",
        "$$Z = {\\tt ReLU}(X) \\implies \\begin{cases}z_{ij} = x_{ij}&{\\mbox{if }}x_{ij}>0\\\\z_{ij} = 0&{\\mbox{otherwise.}}\\end{cases}$$\n",
        "\n",
        "For reference, it is common to use the notation $X = (x_{ij})$ and $Z = (z_{ij})$.\n",
        "\n",
        "**Your Task:** Implement the functions `NUMPY_ReLU` & `PYTORCH_ReLU`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYx9zXS9ZbNS"
      },
      "source": [
        "def NUMPY_ReLU(x):\n",
        "    \"\"\"\n",
        "    Applies the rectified linear unit function element-wise.\n",
        "\n",
        "    Parameters: \n",
        "    x (numpy.ndarray): 2-dimensional numpy array.\n",
        "\n",
        "    Returns: \n",
        "    numpy.ndarray: 2-dimensional numpy array.\n",
        "    \"\"\"\n",
        "    # YOUR CODE STARTS HERE\n",
        "    rel = np.maximum(x, 0)\n",
        "    # YOUR CODE ends HERE\n",
        "\n",
        "    return rel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQL_PfxoaDoR"
      },
      "source": [
        "def PYTORCH_ReLU(x):\n",
        "    \"\"\"\n",
        "    Applies the rectified linear unit function element-wise.\n",
        "\n",
        "    Parameters: \n",
        "    x (torch.Tensor): 2-dimensional torch tensor.\n",
        "\n",
        "    Returns: \n",
        "    torch.Tensor: 2-dimensional torch tensor.\n",
        "    \"\"\"\n",
        "    # YOUR CODE STARTS HERE\n",
        "    rel = torch.relu(x)\n",
        "    # YOUR CODE ends HERE\n",
        "\n",
        "    return rel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQd8n401aE2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0285b4fe-7bc4-42ee-c303-c9fb5daab963"
      },
      "source": [
        "#Test Cases\n",
        "np.random.seed(0)\n",
        "X = np.random.randint(-1000, 1000, size=(3,3))\n",
        "print(NUMPY_ReLU(X))\n",
        "\n",
        "X = torch.from_numpy(X)\n",
        "print(PYTORCH_ReLU(X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0 653]\n",
            " [216   0   0]\n",
            " [731 383  33]]\n",
            "tensor([[  0,   0, 653],\n",
            "        [216,   0,   0],\n",
            "        [731, 383,  33]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reRDSEkyTtuU"
      },
      "source": [
        "# Pytorch Differentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNgOZUQaT_ny"
      },
      "source": [
        "**Exercise #8:** \n",
        "\n",
        "**Your Task**: Determine the derivative of $ y = 2x^3+x $ at $x=1$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2royvcJb35_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0811bf5-da8b-4240-ef43-fe53924ab1b9"
      },
      "source": [
        "# YOUR CODE STARTS HERE\n",
        "x = torch.tensor(1.0, requires_grad= True)\n",
        "y = 2*x**3 + x\n",
        "y.backward()\n",
        "# YOUR CODE ends HERE\n",
        "print('the graid of y wrt x at x = 1 is ',x.grad)\n",
        "assert x.grad.item()==7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the graid of y wrt x at x = 1 is  tensor(7.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnM5TjYAUsv_"
      },
      "source": [
        "**Exercise #9:** \n",
        "\n",
        "**Your Task**: Determine the <b>partial derivative</b> of the function: $f(u,v)=vu+u^{2}$ at $(u,v)=(1,2)$\n",
        "\n",
        "*   with respect to u\n",
        "*   with respect to v\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5lh_HITUXZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe3fdb78-e056-4e81-bdd2-dde6ecf2e589"
      },
      "source": [
        "# YOUR CODE STARTS HERE\n",
        "\n",
        "# Calculate f(u, v) = v * u + u^2 at u = 1, v = 2\n",
        "u = torch.tensor(1.0, requires_grad = True)\n",
        "v = torch.tensor(2.0, requires_grad= True)\n",
        "f = v * u + u**2\n",
        "print(\"The result of v * u + u^2: \", f)\n",
        "\n",
        "# Calculate the derivative with respect to u\n",
        "f.backward()\n",
        "print(\"The partial derivative with respect to u: \", u.grad)\n",
        "\n",
        "# Calculate the derivative with respect to v\n",
        "print(\"The partial derivative with respect to u: \", v.grad)\n",
        "# YOUR CODE ENDS HERE\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result of v * u + u^2:  tensor(3., grad_fn=<AddBackward0>)\n",
            "The partial derivative with respect to u:  tensor(4.)\n",
            "The partial derivative with respect to u:  tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4idmC9bqWB-S"
      },
      "source": [
        "**Exercise #10:** \n",
        "\n",
        "**Your Task**: Visualize the relu activation function and it derivative\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1ldzexvVTL_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "7163f48a-22a2-4920-92f2-f65a57d3bdfa"
      },
      "source": [
        "x = torch.linspace(-3, 3, 100, requires_grad = True)\n",
        "# Take the derivative of Relu with respect to multiple value in x.\n",
        "Y = torch.relu(x)\n",
        "\n",
        "#gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
        "\n",
        "\n",
        "# Plot out the function and its derivative\n",
        "plt.plot(x.detach().numpy(), Y.detach().numpy(), label = 'ReLU function')\n",
        "Y = Y.sum()\n",
        "Y.backward()\n",
        "plt.plot(x.detach().numpy(), x.grad.numpy(), label = 'ReLU derivative')\n",
        "plt.xlabel('x')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2ky6ZT68MnWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GT8yymmbDSpX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}